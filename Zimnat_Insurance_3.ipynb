{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zimnat Insurance 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5rgfwnMGvh6"
      },
      "source": [
        "import pathlib\n",
        "import os \n",
        "import copy\n",
        "import gc \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "import sklearn as sk\n",
        "import lightgbm as lgb\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import chi2\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import feature_selection\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import confusion_matrix\n",
        "!pip install kmodes\n",
        "from kmodes.kmodes import KModes\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "!pip install scikit-optimize\n",
        "import skopt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhiQ73G1G-Se"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G11o4QEjG-aj"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Zimnat Insurance/Data/Train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHhTLmjoagUj"
      },
      "source": [
        "test = pd.read_csv('/content/drive/My Drive/Zimnat Insurance/Data/Test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBr-Cn1wIbu8"
      },
      "source": [
        "preds= pd.read_csv(\"/content/submission1-2.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4_90HtHIgE4"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4ptsHnbHPeW"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIlWVOdoG-iX"
      },
      "source": [
        "np_data = []\n",
        "train_columns = train.columns\n",
        "for v in train.values:\n",
        "  info = v[:8]\n",
        "  binary = v[8:]\n",
        "  index_n = [k for k, i in enumerate(binary) if i == 1]\n",
        "  for i in index_n:\n",
        "    for k in range(len(binary)):\n",
        "      if (k not in index_n) or (k == i):\n",
        "        binary_0 = list(copy.copy(binary))\n",
        "        binary_0[i] = 0\n",
        "        if k == i:\n",
        "          np_data.append(list(info) + binary_0 + [train_columns[8+k]] + [1])\n",
        "        else:\n",
        "          np_data.append(list(info) + binary_0 + [train_columns[8+k]] + [0])\n",
        "\n",
        "df_data = pd.DataFrame(np_data)\n",
        "df_data.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
        "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
        "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
        "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred', 'target']\n",
        "df_data['date1'] = df_data['join_date'].apply(lambda x: x.split('/')[0] if (x == x) else np.nan)\n",
        "df_data['date2'] = df_data['join_date'].apply(lambda x: x.split('/')[1] if (x == x) else np.nan)\n",
        "df_data['date3'] = df_data['join_date'].apply(lambda x: x.split('/')[2] if (x == x) else np.nan)\n",
        "df_data.drop('join_date', axis=1, inplace=True)\n",
        "df_data.drop(columns=[df_data.columns[0],df_data.columns[1]],inplace=True)\n",
        "df_data.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkoiW-LzG-qR"
      },
      "source": [
        "X = pd.concat([df_data.iloc[:,:-4],df_data.iloc[:,-3:]],axis=1)\n",
        "y = df_data.iloc[:,-4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVEr2ZC8G-f0"
      },
      "source": [
        "X_train , X_test , y_train , y_test = sk.model_selection.train_test_split(X,y,test_size=0.3,stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAVQmg3rWEVX"
      },
      "source": [
        "### Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM-yd1WTu31l"
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "models_level_0=[]\n",
        "models_level_0.append((\"catboost\",CatBoostClassifier(n_estimators=10,cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])))\n",
        "models_level_0.append((\"random forest\",RandomForestClassifier()))\n",
        "model_level_1 = CatBoostClassifier(n_estimators=10)\n",
        "clf = StackingClassifier(models_level_0,model_level_1,cv=sk.model_selection.StratifiedKFold(n_splits=3),stack_method=\"predict_proba\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XX1pqURyxjA"
      },
      "source": [
        "clf.fit(X_train.drop(columns=[\"ID\",\"ID2\"]),y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-cvTdThDsBs",
        "outputId": "680d8ede-5fcf-4e10-b84c-0099843d22bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.predict_proba(X_test.drop(columns=[\"ID\",\"ID2\"])).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJQvwZmGEF8_"
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train.drop(columns=[\"ID\",\"ID2\"],axis=1),y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2F5b0euEUBj"
      },
      "source": [
        "rf.predict_proba()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6XFNuAkdwsD"
      },
      "source": [
        "**CatBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUIlMUsbXDm5"
      },
      "source": [
        "cat_features = ['marital_status', 'branch_code','occupation_code','occupation_category_code', 'product_pred']\n",
        "cat = CatBoostClassifier(iterations=3000,learning_rate=0.1,border_count=254,cat_features=cat_features)\n",
        "test_pred_cat,train_pred_cat = Stacking(cat,X_train,y_train,X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv1cpsBqJk6T"
      },
      "source": [
        "test_pred_catboost = pd.DataFrame(test_pred_cat)\n",
        "train_pred_catboost = pd.DataFrame(train_pred_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuMryDWlJ4q6"
      },
      "source": [
        "test_pred_catboost.to_csv(\"catboost_test_predictions.csv\")\n",
        "train_pred_catboost.to_csv(\"catboost_train_predictions.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7rlV3GQd6pz"
      },
      "source": [
        "**Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrfkgP5Kg3XT"
      },
      "source": [
        "x=X\n",
        "x = x.values\n",
        "x = np.concatenate((x[:,:5],x[:,-4:]),axis=1)\n",
        "x_encode = []\n",
        "# label encode each column\n",
        "for i in range(x.shape[1]):\n",
        "  enc = x[:, i]\n",
        "  # store\n",
        "  x_encode.append(enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vUfguBaZsJE"
      },
      "source": [
        "# prepare each input head\n",
        "in_layers = list()\n",
        "em_layers = list()\n",
        "for i in range(9):\n",
        "\t# calculate the number of unique inputs\n",
        "\tn_labels = len(np.unique(x_encode[i]))\n",
        "\t# define input layer\n",
        "\tin_layer = tf.keras.layers.Input(shape=(1,))\n",
        "\t# define embedding layer\n",
        "\tem_layer = tf.keras.layers.Embedding(n_labels, 10)(in_layer)\n",
        "\t# store layers\n",
        "\tin_layers.append(in_layer)\n",
        "\tem_layers.append(em_layer)\n",
        "input2 = tf.keras.layers.Input(shape=(1,21))\n",
        "merge = tf.keras.layers.concatenate(em_layers)\n",
        "merge2 = tf.keras.layers.concatenate([merge,input2],axis=2)\n",
        "flatten = tf.keras.layers.Flatten()(merge2)\n",
        "dense_1 = tf.keras.layers.Dense(128,activation=\"relu\", kernel_initializer='he_normal')(flatten)\n",
        "dropout_1 = tf.keras.layers.Dropout(0.1)(dense_1)\n",
        "dense_2 = tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_1)\n",
        "dropout_2 = tf.keras.layers.Dropout(0.1)(dense_2)\n",
        "dense_3 = tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_2)\n",
        "dropout_3 = tf.keras.layers.Dropout(0.1)(dense_3)\n",
        "output = tf.keras.layers.Dense(1,activation=\"sigmoid\")(dropout_3)\n",
        "neural_network_baseline = tf.keras.Model(inputs=[in_layers,input2],outputs=output)\n",
        "neural_network_baseline.compile(loss=\"binary_crossentropy\",optimizer=tf.keras.optimizers.SGD(0.1),metrics=tf.keras.metrics.BinaryCrossentropy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMXZoSkkaAtX"
      },
      "source": [
        "test_pred_nn,train_pred_nn = Stacking(neural_network_baseline,X_train,y_train,X_test,neural_networks=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvYbRBjMc29P"
      },
      "source": [
        "test_pred_neural_networks = pd.DataFrame(test_pred_nn)\n",
        "train_pred_neural_networks = pd.DataFrame(train_pred_nn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZeBWi-2dO7r"
      },
      "source": [
        "test_pred_neural_networks.to_csv(\"neural_nets_test_predictions.csv\")\n",
        "train_pred_neural_networks.to_csv(\"neural_nets_train_predictions.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS8Dr1FVwDYx"
      },
      "source": [
        "**Light Gradient Boosting Machines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh7iHHZReCXd"
      },
      "source": [
        "def integer_encoder(column):\n",
        "  oe = sk.preprocessing.LabelEncoder()\n",
        "  column = oe.fit_transform(column)\n",
        "  return column "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCNim97Id_XC"
      },
      "source": [
        "X_train = X_train.apply(lambda x : integer_encoder(x) if x.name in X_train.columns[:5] or x.name in X_train.columns[-4:] else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXNLYsf6d_PB"
      },
      "source": [
        "X_test = X_test.apply(lambda x : integer_encoder(x) if x.name in X_test.columns[:5] or x.name in X_test.columns[-4:] else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcCK0Pv3TB1X"
      },
      "source": [
        "from lightgbm import LGBMClassifier \n",
        "clf = LGBMClassifier(num_leaves=25,n_estimators=6000,learning_rate=0.0075)\n",
        "clf.fit(X_train,y_train,eval_set=(X_test,y_test),categorical_feature=[0,1,2,3,4,26,27,28,29],early_stopping_rounds=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpRrYBsFLcaQ"
      },
      "source": [
        "/content/drive/My Drive/Cifar 10 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1Bfr0Iz71Ce"
      },
      "source": [
        "### Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTecKeNt8S-_"
      },
      "source": [
        "np_data_test = []\n",
        "answ_test = []\n",
        "test_columns = test.columns\n",
        "for v in test.values:\n",
        "  info = v[:8]\n",
        "  binary = v[8:]\n",
        "  index_n = [k for k, i in enumerate(binary) if i == 1]\n",
        "  for k in range(len(binary)):\n",
        "    if k not in index_n:\n",
        "      np_data_test.append(list(info) + list(binary) + [test_columns[8+k]])\n",
        "\n",
        "df_data_test = pd.DataFrame(np_data_test)\n",
        "df_data_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
        "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
        "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
        "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYiBLwdu84Pr"
      },
      "source": [
        "df_data_test['date1'] = df_data_test['join_date'].apply(lambda x: x.split('/')[0] if (x == x) else np.nan)\n",
        "df_data_test['date2'] = df_data_test['join_date'].apply(lambda x: x.split('/')[1] if (x == x) else np.nan)\n",
        "df_data_test['date3'] = df_data_test['join_date'].apply(lambda x: x.split('/')[2] if (x == x) else np.nan)\n",
        "df_data_test.drop('join_date', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I5m9AOj9vZw"
      },
      "source": [
        "df_data_test.fillna(0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXCLTC1tMIfG"
      },
      "source": [
        "products=df_data_test[\"product_pred\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5BpL94lELI4"
      },
      "source": [
        "df_data_test = df_data_test.apply(lambda x : integer_encoder(x) if x.name in X_test.columns[:5]  else x)\n",
        "df_data_test = df_data_test.apply(lambda x : integer_encoder(x.astype(int)) if x.name in X_test.columns[-3:] else x)\n",
        "df_data_test = df_data_test.apply(lambda x : integer_encoder(x) if x.name==X_test.columns[-4] else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IcZYMhbDflz"
      },
      "source": [
        "submission = pd.read_csv('/content/SampleSubmission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RslWRhDcPVxb",
        "outputId": "09326350-bc29-491a-f32d-3e76fe0bb2a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds_proba.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9991248378747872"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVLkGG7FDg2H"
      },
      "source": [
        "preds_proba = gbm.predict(df_data_test.drop(['ID',\"sex\"], axis=1))\n",
        "df_answer = df_data_test[['ID']]\n",
        "df_answer['target'] = preds_proba\n",
        "df_answer['ID X PCODE'] = df_answer['ID'] + ' X ' + products\n",
        "df_answer.drop(['ID'], axis=1, inplace=True)\n",
        "df_answer.rename(columns={'target':'Label'}, inplace=True)\n",
        "df_answer = submission[submission['ID X PCODE'].isin(list(set(list(submission['ID X PCODE'])) - set(list(df_answer['ID X PCODE']))))].append(df_answer)\n",
        "df_answer.reset_index(drop=True, inplace=True)\n",
        "df_answer.to_csv('submission_lgbm.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeTlJTGvan_y"
      },
      "source": [
        "### New"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8CziGLbrjrV"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Zimnat Insurance/Data/Train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Zimnat Insurance/Data/Test.csv')\n",
        "submission = pd.read_csv('/content/drive/My Drive/Zimnat Insurance/Data/SampleSubmission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-wShd_yua-o"
      },
      "source": [
        "X_train = []\n",
        "X_train_columns = train.columns\n",
        "c = 0\n",
        "for v in train.values:\n",
        "  info = v[:8]\n",
        "  binary = v[8:]\n",
        "  index = [k for k, i in enumerate(binary) if i == 1]\n",
        "  for i in index:\n",
        "    c+=1\n",
        "    for k in range(len(binary)):\n",
        "      if k == i:\n",
        "        binary_transformed = list(copy.copy(binary))\n",
        "        binary_transformed[i] = 0\n",
        "        X_train.append(list(info) + binary_transformed + [X_train_columns[8+k]] + [c])\n",
        "\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_train.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
        "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
        "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
        "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred', 'ID2']\n",
        "X_test = []\n",
        "true_values = []\n",
        "c = 0\n",
        "for v in test.values:\n",
        "  c += 1\n",
        "  info = v[:8]\n",
        "  binary = v[8:]\n",
        "  index = [k for k, i in enumerate(binary) if i == 1]\n",
        "  X_test.append(list(info) + list(binary) + [c])\n",
        "  for k in test.columns[8:][index]:\n",
        "    true_values.append(v[0] + ' X ' + k)\n",
        "\n",
        "X_test = pd.DataFrame(X_test)\n",
        "X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
        "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
        "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
        "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'ID2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A89N3AcWubnb"
      },
      "source": [
        "features_train = []\n",
        "features_test = []\n",
        "columns = []\n",
        "\n",
        "append_features = ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', \n",
        "'N2MW', 'AHXO','BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', \n",
        "'ECY3', 'ID', 'ID2', 'join_date', 'sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',\n",
        "'birth_year']\n",
        "for v in append_features:\n",
        "  features_train.append(X_train[v].values.reshape(-1, 1))\n",
        "  features_test.append(X_test[v].values.reshape(-1, 1))\n",
        "  columns.append(np.array([v]))\n",
        "\n",
        "y_train = X_train[['product_pred']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh-QhQeFuapt"
      },
      "source": [
        "features_train = np.concatenate(features_train, axis=1)\n",
        "features_test = np.concatenate(features_test, axis=1)\n",
        "columns = np.concatenate(np.array(columns))\n",
        "\n",
        "X_train = pd.DataFrame(features_train)\n",
        "X_train.columns = columns\n",
        "X_test = pd.DataFrame(features_test)\n",
        "X_test.columns = columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r40G2na9RTg"
      },
      "source": [
        "X_train['date1'] = X_train['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
        "X_train['date2'] = X_train['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
        "X_train['date3'] = X_train['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
        "X_train.drop('join_date', axis=1, inplace=True)\n",
        "\n",
        "X_test['date1'] = X_test['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
        "X_test['date2'] = X_test['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
        "X_test['date3'] = X_test['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
        "X_test.drop('join_date', axis=1, inplace=True)\n",
        "\n",
        "X_train['date_diff'] = X_train['date3'] - X_train['birth_year']\n",
        "X_test['date_diff'] = X_test['date3'] - X_test['birth_year']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E33gsxM49Y1K"
      },
      "source": [
        "X_train = X_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "y_train = y_train.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slgDfnT4Ealx"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "data = X_train.append(X_test)\n",
        "for v in [\"sex\",'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',]:\n",
        "  data.loc[:,v] = le.fit_transform(data.loc[:,v])\n",
        "X_train = data[:X_train.shape[0]]\n",
        "X_test = data[-X_test.shape[0]:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf584h879Zns"
      },
      "source": [
        "le = sk.preprocessing.LabelEncoder()\n",
        "le.fit(y_train.iloc[:,0])\n",
        "y_train = pd.DataFrame(le.transform(y_train.iloc[:,0]))\n",
        "y_train.columns = ['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9kRHXmgRPsZ"
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "cat = CatBoostClassifier(learning_rate=0.098003,iterations=2000,save_snapshot=True,snapshot_file=\"/content/drive/My Drive/Colab Notebooks/catboost_info/CatBoost_best\",snapshot_interval=50)\n",
        "cat.fit(X_train,y_train,cat_features=['marital_status','branch_code','occupation_code','occupation_category_code'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m79UMUUQGgzm"
      },
      "source": [
        "proba = cat.predict_proba(X_test.drop(columns=[\"sex\",'ID','ID2'], axis=1))\n",
        "y_test = pd.DataFrame(proba)\n",
        "y_test.columns = le.inverse_transform(y_test.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJHATi5INC9",
        "outputId": "730534ca-11d3-4c29-da89-4a0f74df7b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "proba.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh3ja6nqIV5p"
      },
      "source": [
        "y_test = pd.DataFrame(proba)\n",
        "y_test.columns = le.inverse_transform(y_test.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVr_SGXPIXG-"
      },
      "source": [
        "answer_mass = []\n",
        "for i in range(X_test.shape[0]):\n",
        "  id = X_test['ID'].iloc[i]\n",
        "  for c in y_test.columns:\n",
        "    answer_mass.append([id + ' X ' + c, y_test[c].iloc[i]])\n",
        "\n",
        "df_answer = pd.DataFrame(answer_mass)\n",
        "df_answer.columns = ['ID X PCODE', 'Label']\n",
        "for i in range(df_answer.shape[0]):\n",
        "  if df_answer['ID X PCODE'].iloc[i] in true_values:\n",
        "    df_answer['Label'].iloc[i] = 1.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tis-LQwNJJaw"
      },
      "source": [
        "df_answer.reset_index(drop=True, inplace=True)\n",
        "df_answer.to_csv('submission_best.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}